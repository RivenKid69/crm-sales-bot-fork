# План интеграции ContextWindow (Level 1–3) для роста качества диалогов и продаж

> **Версия:** 1.0  
> **Дата:** 2026-01-08  
> **Статус:** Draft → Ready for implementation

---

## Executive Summary

В проекте уже реализованы 3 уровня контекста (`src/context_window.py`):
- **Level 1 — Sliding Window**: последние N ходов, паттерны зацикливания/повторов, тренд confidence.
- **Level 2 — Structured Context**: turn type, momentum, funnel velocity, engagement (с текущими ограничениями), triggers.
- **Level 3 — Episodic Memory**: долгосрочная память о ключевых эпизодах (первое/повторные возражения, breakthrough, turning points), эффективность действий, клиентский профиль.

Сейчас контекст существует как сильная “наблюдаемость” и частично как “улучшатель классификации”, но он ещё **не используется системно для управления поведением**: тактика (какой *action* выбрать) и стиль (как *сформулировать* ответ) в основном определяются текущим `state + intent + collected_data`.

Цель плана — **поднять качество общения и продаж** за счёт контекста, не разрушив преимущества текущей архитектуры:
- сохранить **детерминированный скелет** (state machine + приоритеты),
- добавить **контекстные “директивы”** к генерации (человечнее, эмпатичнее, без повторов),
- добавить **контекстные оверлеи** к выбору действий (более гибко и уместно),
- сделать всё **fail-safe, обратимым, измеримым и тестируемым** через feature flags, shadow-mode, метрики и сценарные тесты.

---

## 0) Привязка к фазам из `docs/PHASES.md`

Этот план специально “ложится” на модель релизов из `docs/PHASES.md`: постепенность, обратимость, тестируемость и измеримость через feature flags.

**Как читать:**
- в этом документе описаны *новые* интеграции контекста (L1–L3) и как их безопасно включать;
- в `docs/PHASES.md` уже есть каркас фаз 0–5 — мы внедряем контекст **внутри этих фаз**, не создавая “параллельную дорожную карту”.

**Ключевой принцип привязки:**  
сначала *инструменты измерения и сбор контекста* (Phase 0), затем *человечность без изменения логики* (Phase 2), затем *узкие оверлеи поведения* (Phase 3), и только после этого — более рискованные сигналы и расширения.

## 1) Цели, метрики и инварианты

### 1.1 Цели качества общения (UX)
Цель: “бот не как робот” измеряется не словами, а поведением:
- меньше повторов и “холостых” вопросов,
- больше “grounding”: бот помнит и ссылается на уже сказанное (без навязчивости),
- корректный repair: бот умеет чинить непонимание (уточнить/перефразировать/суммировать),
- эмпатия уместна и краткая (особенно при фрустрации),
- ответы соответствуют стадии SPIN и не прыгают вперёд.

**Предлагаемые метрики (Phase 0 / metrics.py):**
- `repeat_question_rate`: доля диалогов, где клиент задаёт “тот же вопрос” ≥ 2 раз.
- `stuck_rate`: доля диалогов с `is_stuck=True` ≥ 1 раза.
- `oscillation_rate`: доля диалогов с `has_oscillation=True`.
- `fallback_rate` и `fallback_tier_distribution` (уже есть база).
- `avg_turns_to_value`: среднее число ходов до первого “value moment” (определяем как: заполнены ключевые `required_data` + первый переход в `presentation`).
- `clarification_success_rate`: доля repair-ходов, которые приводят к прогрессу в следующие 1–2 хода.

### 1.2 Цели продаж (Business)
Цель: конверсия и прогресс по SPIN, без ухудшения UX:
- `demo_request_rate` / `contact_provided_rate` (уже можно считать по `intents_sequence`).
- `avg_turns_to_demo` / `avg_turns_to_contact`.
- `soft_close_rate` (особенно “ранний” soft_close до `presentation`).
- `objection_resolution_rate`: доля возражений, после которых в следующие N ходов происходит прогресс (например, agreement/demo_request/data_provided).

### 1.3 Нерушимые инварианты (анти-регрессии)
Чтобы “плюсы архитектуры не пропали”, вводим правила:
1. **Fail-safe**: если контекст отсутствует/неполный → поведение как сейчас.
2. **Reversible**: каждую интеграцию включаем отдельным feature flag; откат = выключить флаг.
3. **No hard-branching on noisy signals**: пока engagement считается по длине, он **не** влияет на выбор state/action (разрешён только как стиль/тон).
4. **State machine остаётся source-of-truth**: контекстные оверлеи не должны ломать инварианты SPIN и приоритеты.
5. **Explainable**: любое контекстное решение логируется reason codes (почему и на каких сигналах).

---

## 2) Ключевая идея: разделить “Что делаем” и “Как говорим”

Это основной best practice для безопасного улучшения диалогов:
- **Policy (что делаем)**: выбираем действие/тактику (action), опираясь на state, intent, данные и контекстные сигналы.
- **Generation (как говорим)**: формируем ответ в нужном стиле/структуре, опираясь на те же сигналы, но без изменения логики SPIN.

Так мы повышаем “человечность” без риска сломать flow, а затем точечно улучшаем flow.

### 2.1 Принципы “не робот” (как должны выглядеть ответы)
Эти правила можно воплотить через `ResponseDirectives` и шаблоны генератора:
1. **Grounding**: ссылка на то, что клиент уже сказал (“Понял, вы упоминали…”) — только на факты из `collected_data`/episodic memory.
2. **Validation**: короткое признание эмоции/ситуации (“Понимаю, цена важна…”) — 1 фраза, без “психологизации”.
3. **One-question rule**: максимум 1 ключевой вопрос в конце, если не режим вариантов.
4. **Progressive disclosure**: не “вываливать” презентацию раньше времени; сначала уточнить/квалифицировать.
5. **Choice architecture**: когда клиент “застрял” — давать 2–3 простых варианта ответа (а не открытый вопрос).
6. **Repair first**: при `is_stuck`/низком confidence — сначала починить понимание, потом продавать.
7. **No creepiness**: не цитировать пользователя “по ходам” и не демонстрировать “тотальную память”; помнить полезное, но деликатно.

---

## 3) Как именно использовать Level 1–3 (карта применений)

### 3.1 Level 1 (последние N ходов) — “repair и анти-зацикливание”
Используем для:
- `repeated_question` → “ответ + короткое резюме + уточнение”, без раздражения.
- `is_stuck` / `unclear_count` → стратегия repair: перефразировать, задать один конкретный вопрос, предложить варианты ответа.
- `has_oscillation` → снизить “давление”: больше вопросов-уточнений, меньше pitch, фиксация понимания.
- `confidence_trend=decreasing` → переход на более консервативные действия (уточнение вместо шага вперёд).

**Важно:** это улучшает UX и снижает “бесконечные ветки”, сохраняя state machine.

### 3.2 Level 2 (структурные сигналы) — “темп и уместность”
Используем осторожно:
- `turn_types` / `turn_type_counts` / `is_progressing` / `is_regressing` → оценка направления беседы, выбор: ускориться / стабилизировать / чинить.
- `momentum_direction` → если устойчиво положительный, можно чуть быстрее переходить к следующему шагу *в рамках SPIN*.
- `funnel_velocity` → сигнал “готовности к следующему шагу” (использовать как *bias*, не как жёсткий if).

**Ограничение:** `engagement_*` пока зависит от `word_count` → применять только как стилистику (длина ответа, больше/меньше “воды”), не как развилку.

### 3.3 Level 3 (episodic memory) — “персонализация и долгие диалоги”
Это самый безопасный и полезный слой для продаж:
- `first_objection_type` / `repeated_objection_types` / `total_objections` → стратегия обработки возражений и эскалация тактики (не повторять одинаковый скрипт).
- `has_breakthrough` / `breakthrough_action` / `turns_since_breakthrough` → не упускать “момент закрытия” (мягкий CTA).
- `most_effective_action` / `least_effective_action` / `successful_actions` / `failed_actions` → избегать того, что уже не работает, и повторять эффективное.
- `client_*` (профиль) → “не как робот”: помнить контекст клиента и формулировать точнее (но без “криповости”).

---

## 4) Предлагаемая интеграция в текущую архитектуру (минимально-инвазивно)

### 4.1 Новые “прослойки” без ломки системы
Добавляем две небольшие сущности:

1) **ContextEnvelope** (единый контракт контекста)
- собирается в `src/bot.py` один раз на ход,
- включает: базовый контекст + `context_window.get_classifier_context()` + tone/guard результаты,
- используется и для классификатора, и для policy, и для генератора.

2) **ResponseDirectives** (директивы для генерации)
- не меняют state machine,
- задают стиль/структуру: эмпатия, краткость, one-question rule, “ссылка на ранее сказанное”, формат ответа.

Опционально (следующим шагом) — **DialoguePolicy**:
- принимает `intent`, `state_machine` результат и `ContextEnvelope`,
- возвращает `action_override` (только в узких безопасных случаях) + reason codes.

### 4.2 Предлагаемая схема ResponseDirectives (минимально достаточная)
Пример структуры (как словарь в `context` для генератора):
```python
response_directives = {
    "style": {
        "tone": "empathetic|neutral|confident",
        "max_words": 60,
        "one_question": True,
        "use_bullets": False,
    },
    "dialogue_moves": {
        "validate": True,
        "summarize_client": True,
        "ask_clarifying": False,
        "offer_choices": False,
        "cta_soft": True,
    },
    "memory": {
        "client_card": "…короткое резюме фактов…",
        "objection_summary": "…что уже было…",
        "do_not_repeat": "…что не спрашивать снова…",
    },
    "reason_codes": ["repair.stuck", "objection.repeat.price"],
}
```
Ключевое: директивы **не требуют** менять state machine, но резко повышают ощущение “живого” диалога.

### 4.2 Где именно это встраивается

```
SalesBot.process()
  ├─ ToneAnalyzer / Guard (уже есть)
  ├─ ContextEnvelopeBuilder  ← (новое: единый сбор контекста)
  ├─ HybridClassifier.classify(message, context=envelope_for_classifier)
  ├─ StateMachine.process(intent, extracted_data)  ← базовый skeleton
  ├─ DialoguePolicy.maybe_override(sm_result, envelope)  ← (feature-flag)
  ├─ ResponseDirectivesBuilder(envelope, sm_result)  ← (feature-flag)
  └─ Generator.generate(action, context + directives + summary)
```

Эта схема максимально сохраняет существующие достоинства:
- state machine остаётся главным источником переходов,
- контекст управляет либо стилем, либо узкими оверлеями,
- всё выключается флагами.

---

## 5) План внедрения по фазам (`docs/PHASES.md`)

Ниже — тот же план, но разложенный по фазам из `docs/PHASES.md`: так проще включать фичи постепенно, измеримо и с быстрым откатом.

### 5.0 Таблица флагов и критериев включения

> Таблица описывает **новые** флаги из этого плана. Флаги из `docs/PHASES.md` (например, `metrics_tracking`, `tone_analysis`) остаются как есть и используются как зависимости.

| Фаза (`docs/PHASES.md`) | Новые флаги (этот план) | Default | Что даёт | Входные критерии | Выходные критерии |
|---|---|---:|---|---|---|
| 0 — Инфраструктура | `context_full_envelope`, `context_shadow_mode` | `false` | Полный контекст собирается/логируется без изменения поведения | Базовые тесты и Phase 0 метрики стабильны | 0 регрессий при `false`, есть reason codes и shadow-метрики |
| 1 — Защита и надёжность | — | — | Приоритеты контроллеров, PII redaction, защита от prompt injection | Phase 0 готова | Сценарии “guard/disamb/fallback” стабильны, нет PII в summary/логах |
| 2 — Естественность диалога | `context_response_directives` | `false` | “Не робот”: краткие директивы, repair, grounding без изменения state machine | Phase 0–1 готовы | Не растёт `fallback_rate`, падают `repeat_question_rate`/`stuck_rate` |
| 3 — Оптимизация SPIN Flow | `context_policy_overlays`, `context_engagement_v2` | `false` | Узкие, объяснимые action-overrides на стабильных сигналах | Phase 2 в норме | `action_override_rate` низкий, нет роста раннего `soft_close_rate` |
| 4 — Intent Disambiguation | — | — | Контекстно-осмысленное уточнение, корректная запись disambiguation ходов | Phase 0–3 готовы | Снижение ошибок интента без роста “лишних уточнений” |
| 5 — Dynamic CTA Fallback | `context_cta_memory` | `false` | CTA/фоллоу-ап с учётом episodic memory (без “криповости”) | Phase 0–4 готовы | Рост конверсии в следующий шаг без роста отказов |

### Фаза 0: Инфраструктура (`docs/PHASES.md` Phase 0)

#### Этап 0 — Базовая измеримость (до любых изменений поведения)
**Зачем:** нельзя гарантировать улучшение без baseline и метрик.

**Изменения:**
- Добавить логирование reason codes для всех текущих “особых” решений (guard intervention, fallback, disambiguation, objection soft_close).
- Добавить метрики “фрикции”: stuck/oscillation/repeated_question occurrences (на основе ContextWindow).
- Добавить “shadow counters”: сколько раз новые policy-решения *могли бы* сработать (без применения).

**Acceptance criteria:**
- Метрики есть, тесты проходят, latency не растёт заметно.

**Quality gate (stop/rollback):**
- если после включения логирования растёт error-rate/latency → откатить, оптимизировать, повторить.

---

#### Этап 1 — Единый сбор контекста (данные → без изменения поведения)
**Цель:** чтобы L2/L3 реально доходили до классификатора/генератора, но не меняли flow пока флаг выключен.

**Изменения (минимальные):**
- В `src/bot.py` собрать `ContextEnvelope` как merge:
  - базовый контекст (`state`, `spin_phase`, `missing_data`, `last_action`, …),
  - `self.context_window.get_classifier_context()` (все уровни),
  - tone/guard поля (frustration, tone).
- Включение через flag: `context_full_envelope` (по умолчанию `false`).
- При `false` — старый контекст как сейчас.

**Тесты:**
- Юнит: проверка, что merge не затирает ключи и имеет стабильную схему.
- Интеграционные: при выключенном флаге поведение полностью совпадает (action/state) на фиксированных сценариях.

**Quality gate:**
- 0 изменений поведения при `context_full_envelope=false`.

---

### Фаза 1: Защита и надёжность (`docs/PHASES.md` Phase 1)

**Задача фазы:** гарантировать, что новые контекстные интеграции не ухудшают fail-safe свойства системы и не создают “скрытых” рисков.

**Что делаем в рамках этого плана (без изменения продажного flow):**
- Фиксируем и тестируем порядок контроллеров в `src/bot.py` (подробнее в разделе 6.2): `guard` → `disambiguation` → `fallback` → `objection_handler/flow` → `policy overlays` → `state_machine`.
- Добавляем PII redaction для `context_summary` и логов (подробнее в разделе 11.3).
- Усиливаем устойчивость к prompt injection: в шаблонах явно разделяем *инструкции* / *контекст как данные* / *сообщение пользователя* (раздел 11.2).

**Критерии включения:** Phase 0 завершена, тесты guard/fallback/disambiguation стабильны.  
**Критерии выхода:** нет PII в summary/логах, сценарии “guard/disamb/fallback” проходят без изменений поведения при выключенных флагах контекста.

### Фаза 2: Естественность диалога (`docs/PHASES.md` Phase 2)

#### Этап 2 — “Человечность” через ResponseDirectives (стиль, не логика)
**Цель:** сделать ответы менее роботическими без риска поломки SPIN.

**Идея:** генерируем короткую, детерминированную “память/карточку” и директивы:
- “что мы знаем о клиенте” (company size, отрасль, боль),
- “что уже обсуждали” (первое возражение, повторные возражения),
- “как отвечать сейчас” (эмпатично/кратко/1 вопрос/суммировать).

**Изменения:**
- Добавить `ResponseDirectivesBuilder` (лучше отдельный файл, например `src/response_directives.py`):
  - вход: `ContextEnvelope` + `sm_result`,
  - выход: `directives` (структура) + короткий `context_summary` (строка).
- Пробросить `context_summary` и директивы в `src/generator.py` через `context`:
  - добавить переменные для шаблонов (`{context_summary}`, `{client_card}`, `{do_not_repeat}`).
- Включение через flag: `context_response_directives`.

**Правила безопасности (best practices):**
- summary короткий (например, ≤ 6 строк) и без персональных данных (телефон/email).
- “ссылка на ранее сказанное” только по бизнес-данным (боль/размер/инструменты), без “вы говорили 3 хода назад…”.

**Тесты:**
- Юнит: summary builder (формат, ограничения длины, отсутствие PII).
- Интеграционные: генератор получает новые переменные; при выключенном флаге — старые шаблоны работают.

**Ожидаемый эффект:**
- лучшее ощущение памяти и уместности без изменения state machine.

**Quality gate:**
- не допускаем роста `fallback_rate` и “иностранного текста” (англ/кит) из-за усложнения промпта.

---

### Фаза 3: Оптимизация SPIN Flow (`docs/PHASES.md` Phase 3)

#### Этап 3 — Safe Policy Overlays (контекст влияет на action, но узко)
**Цель:** добавить гибкость и “умность” в поведение, не ломая flow.

**Стратегия:** сначала только “железобетонные” сигналы:
- `has_breakthrough`, `turns_since_breakthrough`,
- `repeated_objection_types`, `total_objections`,
- `most_effective_action` / `least_effective_action`,
- `is_stuck` / `repeated_question` (как repair).

**Изменения:**
- Добавить `DialoguePolicy` (например, `src/dialogue_policy.py`) с методом:
  - `maybe_override(sm_result, envelope) -> {action, next_state, reason_codes} | None`
- В `src/bot.py` после `state_machine.process()` применить override *только если* включён флаг `context_policy_overlays`.

**Примеры оверлеев (консервативные):**
1. **Repeated objection escalation**: если текущее возражение повторяется → выбрать action “reframe_value”/“handle_repeated_objection” вместо повторения того же.
2. **Breakthrough window**: если был breakthrough и мы в `presentation/handle_objection`, и интент позитивный → добавить CTA “следующий шаг” (не обязательно менять state, но можно менять action).
3. **Repair mode**: если `is_stuck` или повторный вопрос → action “clarify_one_question” (сохраняем state).

**Тесты (обязательны):**
- Юнит: каждый оверлей (входные сигналы → ожидаемый override + reason).
- Интеграционные: на наборах сценариев сравнить последовательность state/action:
  - при выключенном флаге — совпадает с baseline,
  - при включенном — меняется только там, где ожидается.

**Анти-паттерны (запрещено на этом этапе):**
- soft_close на основе engagement (пока метрика noisy),
- пропуск SPIN фаз “по momentum”,
- любые hard-branching правила без стабильных сигналов.

**Quality gate:**
- доля overridden action (action_override_rate) сначала должна быть низкой (например, < 5–10%),
- если override приводит к росту `stuck_rate`/`soft_close_rate` → откатить правило по reason code.

---

#### Этап 4 — Перерасчёт engagement (сделать пригодным для решений)
**Цель:** превратить engagement из “длина текста” в “смысловую вовлечённость”.

**Предлагаемый пересчёт (без LLM):**
- опираться на `has_data`, `question_count`, `turn_type`, `repeated_question`, `rejection/objection` частоту,
- убрать прямую зависимость от `word_count` или сильно уменьшить вес,
- добавить “положительный короткий ответ” (да/ок/понял) как норму, а не disengaged.

**Тесты:**
- Юнит на короткие реплики (“да”, “ок”, “понял”) в разных контекстах.
- Интеграционные: engagement больше не провоцирует ложные “disengaged”.

Только после этого разрешать использовать engagement для policy decisions.

---

### Фаза 4: Intent Disambiguation (`docs/PHASES.md` Phase 4)

**Задача фазы:** снижать ошибки интента при неоднозначности, не раздражая пользователя “лишними уточнениями”.

**Как контекст помогает (безопасно):**
- использовать `confidence_trend`, `is_stuck`, `repeated_question` как сигналы “не уверены — лучше уточнить/переформулировать”;
- записывать disambiguation-ходы в ContextWindow, чтобы не терять память о них и улучшать дальнейший repair/тон;
- логировать reason codes “почему спросили уточнение”.

**Критерии включения:** Phase 2–3 стабильны, есть baseline по disambiguation rate.  
**Критерии выхода:** меньше ошибок интента и нет роста “повторов уточнений”.

### Фаза 5: Dynamic CTA Fallback (`docs/PHASES.md` Phase 5)

**Задача фазы:** делать CTA (в fallback и в обычных ходах) уместнее за счёт episodic memory, не ломая текущие правила CTA/objection-flow.

**Как использовать L3 без риска:**
- если `repeated_objection_types` содержит `objection_price` → CTA про ROI/рассрочку/варианты тарифа (без давления);
- если был `has_breakthrough` недавно → CTA “следующий шаг” (демо/контакт) мягко и кратко;
- если `most_effective_action` известен → предпочитать CTA/формулировку, которая уже работала.

**Критерии включения:** Phase 0–4 стабильны, `dynamic_cta_fallback` и/или `cta_generator` проходят тесты.  
**Критерии выхода:** рост переходов в следующий шаг без увеличения отказов/soft_close.

### Кросс-фазный релиз: оценка качества и rollouts (для фаз 0–5)

#### Этап 5 — Оценка качества: сценарии, shadow-mode и A/B
**Цель:** доказать “качество выросло” без случайных даунгрейдов.

**Offline (обязательно):**
- Набор **реалистичных диалоговых сценариев** (tests/fixtures), включая:
  - длинные диалоги,
  - повторные возражения,
  - непонимание (unclear),
  - возвраты назад (circular flow),
  - disambiguation.
- Сценарные тесты проверяют:
  - последовательность action/state,
  - наличие нужных директив/summary в контексте генератора,
  - reason codes (какие правила сработали).

**Shadow-mode (в проде/стенде):**
- policy считает overrides, но не применяет,
- логируем “что бы изменилось” + контекст,
- оцениваем частоту и потенциальные риски.

**Online (если есть возможность):**
- A/B: включаем флаги на небольшой доле,
- сравниваем `demo_request_rate`, `soft_close_rate`, `repeat_question_rate`, latency, fallback.

**Quality gate:**
- заранее определить “красные линии” (например, `soft_close_rate +2%` или `fallback_rate +1%` → стоп и rollback),
- любая деградация должна быть локализуема до конкретного флага/правила.

---

## 6) Защитные механизмы (guardrails)

### 6.1 Reason codes и объяснимость
Любое контекстное решение должно иметь:
- `decision_id` (например, `policy.repair.stuck`),
- `signals_used` (например, `unclear_count=3`, `is_stuck=True`),
- `expected_effect` (“clarify and recover”).

Это позволяет быстро откатить конкретное правило без “магии”.

### 6.2 Конфликт-менеджмент между подсистемами
В проекте уже есть:
- `conversation_guard` (Phase 1),
- `objection_flow` (Phase 3),
- `intent_disambiguation` (Phase 4),
- `fallback_handler` (Phase 1/5).

Правило: **policy overlays не должны обходить guard** и не должны дублировать flow-менеджеры.
При конфликте приоритетов: `guard` → `disambiguation` → `fallback` → `objection_handler/flow` → `policy overlays` → `state_machine`.

---

## 7) Конкретный список работ (чеклист)

### 7.1 Документирование контракта контекста
- Описать ключи `ContextEnvelope` (какие обязательные/опциональные, типы).
- Зафиксировать “safe vs noisy signals”.

### 7.2 Код (по этапам)
- `src/bot.py`: ContextEnvelopeBuilder + feature flags.
- `src/response_directives.py` (новый): builder директив и summary.
- `src/generator.py` + `src/config.py`: поддержка новых переменных в шаблонах.
- `src/dialogue_policy.py` (новый): safe overlays + reason codes.
- `src/metrics.py`: метрики использования контекста/оверлеев.

### 7.3 Тесты
- `tests/test_context_envelope.py` (новый): схема/merge.
- `tests/test_response_directives.py` (новый): summary, PII, rules.
- `tests/test_dialogue_policy.py` (новый): overlays.
- `tests/test_context_integration_scenarios.py` (новый): реалистичные сценарии на action/state.

---

## 8) Почему это должно улучшить качество (коротко)

Это следует из практик conversational UX и безопасной инженерии диалоговых систем:
- “Память” и “grounding” снижают повторения и повышают доверие.
- Repair-стратегии уменьшают фрустрацию и зацикливание.
- Разделение policy/generation позволяет улучшать эмпатию без поломки flow.
- Постепенное включение через флаги + измеримость даёт прирост без “случайных даунгрейдов”.

---

## 9) Приложение: таблица сигналов (рекомендуемое использование)

| Сигнал | Источник | Использование сейчас | Рекомендуемое использование | Риск |
|---|---|---:|---|---|
| `is_stuck`, `unclear_count` | L1 | частично (classifier) | repair directives + policy overlay | низкий |
| `repeated_question` | L1 | частично | answer+summary+clarify | низкий |
| `confidence_trend` | L1 | есть | conservative mode / clarification | средний |
| `momentum_direction` | L2 | есть в classifier, но не в runtime | только bias (не hard rule) | средний |
| `funnel_velocity` | L2 | аналитика | мягкий CTA/ускорение внутри SPIN | средний |
| `engagement_*` | L2 | аналитика | стиль (краткость), не ветки | высокий (пока) |
| `repeated_objection_types` | L3 | есть в classifier | эскалация тактики, не повторять скрипт | низкий |
| `has_breakthrough` | L3 | есть в classifier | “не упустить момент” (CTA) | низкий |
| `most/least_effective_action` | L3 | есть в контексте | avoid/repeat strategies | средний |

---

## 10) Итоговая стратегия внедрения (коротко)

1) **Сначала**: метрики/observability + единый ContextEnvelope (без изменения поведения).  
2) **Потом**: “человечность” через директивы и краткий summary в промптах (минимальный риск).  
3) **Затем**: узкие safe overlays в policy (контекст влияет на action).  
4) **Только потом**: перерасчёт engagement и расширение контекстных решений.  
5) **Всегда**: feature flags, shadow-mode, сценарные тесты и A/B.

---

## 11) Критический обзор (риски и меры) — с позиции лучших практик

Ниже — “что может пойти не так” и как это заранее обезвредить, чтобы не получить случайные даунгрейды.

### 11.1 Риск: “просто добавили контекст в промпт” → ухудшение качества
**Почему это бывает:** LLM может игнорировать директивы, путаться из-за лишней информации, либо начинать “галлюцинировать память”.

**Меры:**
- Передавать в LLM **не весь контекст**, а *минимальный*, детерминированно собранный `context_summary` (короткий, структурный, без предположений).
- Директивы держать в **структурированном виде** и ограничивать их число (3–5 ключевых пунктов на ход).
- Добавить **детерминированные проверки** результата: лимит вопросов (1), лимит длины, отсутствие “криповых” ссылок (“вы говорили 7 ходов назад…”).

### 11.2 Риск: prompt injection / “клиент попросил игнорировать правила”
**Почему это важно:** пользовательский текст и история — недоверенные данные; если они оказываются рядом с инструкциями, модель иногда “переучивается” на них.

**Меры:**
- Явно разделять в шаблоне: *системные инструкции* (system) → *контекст как данные* → *сообщение пользователя*.
- Никогда не интерпретировать user_message как инструкции для системы (это должно быть прописано в system prompt).
- Не давать пользователю “видеть” служебные директивы и reason codes в ответе.

### 11.3 Риск: утечки/логирование PII из episodic memory
**Почему это важно:** телефон/email/ФИО могут попасть в summary, логи и промпты.

**Меры:**
- В `context_summary` и логах по умолчанию **редактировать PII** (маскирование).
- Хранить PII отдельно, использовать только там, где это нужно (например, подтверждение контакта), а не как “память для стиля”.
- В тестах обязательно проверять отсутствие PII в summary/логах.

### 11.4 Риск: конфликт контроллеров (Guard/Disambiguation/ObjectionFlow/Policy)
**Почему это бывает:** несколько подсистем начинают одновременно “рулить” action, и поведение становится непредсказуемым.

**Меры:**
- Жёстко зафиксировать приоритеты (как в разделе 6.2) и реализовать их в одном месте в `bot.py`.
- Для каждого override писать reason codes + метрику `action_override_rate` и распределение по reason.

### 11.5 Риск: использование noisy-сигналов (engagement по длине) ломает UX
**Почему это бывает:** короткие “да/ок” — нормальные ответы, но текущая формула может их считать disengaged.

**Меры:**
- До переработки engagement (Этап 4) использовать `engagement_*` **только для стиля**, но не для ветвления.
- Любую попытку “soft_close по engagement” запрещать на уровне policy.

### 11.6 Риск: “усложнили систему, но не доказали улучшение”
**Почему это бывает:** локальные тесты проходят, но в реальных диалогах меняется распределение запросов.

**Меры:**
- До внедрения — baseline метрики (Этап 0).
- После внедрения — shadow-mode и canary rollout (малый процент).
- Для качества ответов добавить **ручную оценку** на “golden set” диалогов (pairwise предпочтение/рубрика), потому что автоматические метрики часто слепы к “человечности”.
