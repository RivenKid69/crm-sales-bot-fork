#!/usr/bin/env python3
"""
E2E Stress Test: Dialog Context Memory & Retention.

Tests how the bot remembers and uses conversation context across turns.

Key areas tested:
  1. FACT RETENTION â€” facts mentioned early in conversation, checked later
  2. HISTORY WINDOW â€” what the model actually sees (4 vs 30 turns)
  3. EPISODIC MEMORY â€” pain_points, company data persistence in ContextWindow
  4. CONTEXT AFTER COMPACTION â€” what survives history_compact (and does it even get used?)
  5. LONG DIALOG DEGRADATION â€” quality over 15-20+ turn conversations
  6. REPETITION / DEDUP â€” does the bot avoid repeating itself in long dialogs

Usage:
  python tests/e2e_context_memory_stress.py                    # full run
  python tests/e2e_context_memory_stress.py --flow autonomous  # autonomous only
  python tests/e2e_context_memory_stress.py --flow spin_selling # spin only
  python tests/e2e_context_memory_stress.py --compact          # summary only
"""

import sys
import os
import time
import json
import re
import argparse
from typing import List, Dict, Any, Optional, Tuple
from collections import defaultdict
from dataclasses import dataclass, field

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.llm import OllamaLLM
from src.bot import SalesBot
from src.context_window import ContextWindow


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Test Scenario Definitions
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class FactMarker:
    """A specific fact injected into conversation to track retention."""
    name: str           # e.g. "company_name"
    value: str          # e.g. "ÐÐµÑ„Ñ‚ÐµÐ¢Ñ€Ð°Ð½ÑÐ¡ÐµÑ€Ð²Ð¸Ñ"
    injected_at: int    # turn number where fact is introduced
    check_at: List[int] # turn numbers where we probe for this fact
    check_keywords: List[str]  # keywords to look for in bot response


@dataclass
class ConversationTurn:
    """A single user message in a scripted scenario."""
    message: str
    description: str = ""  # what this turn tests
    expect_in_response: List[str] = field(default_factory=list)  # keywords expected
    expect_not_in_response: List[str] = field(default_factory=list)  # should NOT appear
    is_probe: bool = False  # True if this turn probes for earlier context
    probe_fact: str = ""    # which fact we're probing for


@dataclass
class TurnResult:
    """Result of a single conversation turn."""
    turn_num: int
    user_message: str
    bot_response: str
    intent: str
    state: str
    description: str
    # History analysis
    history_len: int
    history_formatted_len: int  # chars in formatted history sent to LLM
    # Context window state
    cw_turns: int
    episodic_episodes: int
    episodic_pain_points: List[str]
    episodic_client_data: Dict[str, Any]
    # Fact checks
    fact_checks: Dict[str, bool] = field(default_factory=dict)  # fact_name -> found_in_response
    # Dedup
    similarity_to_prev: float = 0.0
    elapsed_ms: float = 0.0


@dataclass
class ScenarioResult:
    """Full result of a test scenario."""
    scenario_name: str
    flow_name: str
    turns: List[TurnResult]
    fact_markers: List[FactMarker]
    # Aggregates
    total_turns: int = 0
    facts_retained: int = 0
    facts_lost: int = 0
    total_elapsed_s: float = 0.0
    avg_response_len: float = 0.0
    dedup_violations: int = 0  # turns with high similarity to previous
    history_compact_used: bool = False  # was history_compact ever injected


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Scenario 1: LONG B2B DIALOG with fact injection & probing
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SCENARIO_LONG_DIALOG = {
    "name": "Long B2B Dialog â€” 18 turns, fact retention stress",
    "description": """
    Simulates a realistic long B2B sales conversation.
    Injects specific facts at turns 1-5, then probes for them at turns 10-18.
    Tests: history window limits, episodic memory, context degradation.
    """,
    "fact_markers": [
        FactMarker("company_name", "ÐÐµÑ„Ñ‚ÐµÐ¢Ñ€Ð°Ð½ÑÐ¡ÐµÑ€Ð²Ð¸Ñ", 1, [8, 12, 17], ["ÐÐµÑ„Ñ‚ÐµÐ¢Ñ€Ð°Ð½ÑÐ¡ÐµÑ€Ð²Ð¸Ñ", "Ð½ÐµÑ„Ñ‚ÐµÑ‚Ñ€Ð°Ð½Ñ"]),
        FactMarker("employee_count", "450", 2, [10, 15], ["450"]),
        FactMarker("pain_point", "Ñ€ÑƒÑ‡Ð½Ð¾Ð¹ ÑƒÑ‡Ñ‘Ñ‚ Ð·Ð°ÑÐ²Ð¾Ðº Ð² Excel", 3, [11, 16], ["excel", "Ñ€ÑƒÑ‡Ð½Ð¾Ð¹", "Ð·Ð°ÑÐ²Ðº"]),
        FactMarker("contact_name", "ÐÐ»ÐµÐºÑÐµÐ¹ ÐŸÐµÑ‚Ñ€Ð¾Ð²Ð¸Ñ‡", 1, [9, 14], ["ÐÐ»ÐµÐºÑÐµÐ¹", "ÐŸÐµÑ‚Ñ€Ð¾Ð²Ð¸Ñ‡"]),
        FactMarker("budget_range", "2 Ð¼Ð¸Ð»Ð»Ð¸Ð¾Ð½Ð° Ñ€ÑƒÐ±Ð»ÐµÐ¹", 5, [13, 17], ["2 Ð¼Ð¸Ð»Ð»Ð¸Ð¾Ð½", "2 Ð¼Ð»Ð½", "Ð±ÑŽÐ´Ð¶ÐµÑ‚"]),
    ],
    "turns": [
        # === TURN 1: greeting + inject company & contact ===
        ConversationTurn(
            message="Ð”Ð¾Ð±Ñ€Ñ‹Ð¹ Ð´ÐµÐ½ÑŒ! ÐœÐµÐ½Ñ Ð·Ð¾Ð²ÑƒÑ‚ ÐÐ»ÐµÐºÑÐµÐ¹ ÐŸÐµÑ‚Ñ€Ð¾Ð²Ð¸Ñ‡, Ñ Ð¸Ð· ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸ ÐÐµÑ„Ñ‚ÐµÐ¢Ñ€Ð°Ð½ÑÐ¡ÐµÑ€Ð²Ð¸Ñ. ÐÐ°Ð¼ Ð¿Ð¾ÑÐ¾Ð²ÐµÑ‚Ð¾Ð²Ð°Ð»Ð¸ Ð²Ð°Ñˆ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚.",
            description="Greeting + inject company_name + contact_name",
        ),
        # === TURN 2: inject employee count ===
        ConversationTurn(
            message="Ð£ Ð½Ð°Ñ Ð² ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸ 450 ÑÐ¾Ñ‚Ñ€ÑƒÐ´Ð½Ð¸ÐºÐ¾Ð², Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÐ¼ Ð² Ð»Ð¾Ð³Ð¸ÑÑ‚Ð¸ÐºÐµ Ð¸ Ñ‚Ñ€Ð°Ð½ÑÐ¿Ð¾Ñ€Ñ‚Ðµ Ð½ÐµÑ„Ñ‚ÐµÐ¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¾Ð².",
            description="Inject employee_count + industry",
        ),
        # === TURN 3: inject pain point ===
        ConversationTurn(
            message="ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° â€” Ð²ÐµÑÑŒ ÑƒÑ‡Ñ‘Ñ‚ Ð·Ð°ÑÐ²Ð¾Ðº Ð²ÐµÐ´Ñ‘Ð¼ Ð² Excel Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ, Ð¿Ð¾ÑÑ‚Ð¾ÑÐ½Ð½Ð¾ Ñ‚ÐµÑ€ÑÑŽÑ‚ÑÑ Ð´Ð°Ð½Ð½Ñ‹Ðµ, Ð´ÑƒÐ±Ð»Ð¸.",
            description="Inject pain_point (manual Excel tracking)",
        ),
        # === TURN 4: normal conversation ===
        ConversationTurn(
            message="Ð”Ð°, Ð¿Ñ€Ð¾Ð±Ð¾Ð²Ð°Ð»Ð¸ Ð¿Ð°Ñ€Ñƒ CRM Ñ€Ð°Ð½ÑŒÑˆÐµ, Ð½Ð¾ Ð¾Ð½Ð¸ Ð±Ñ‹Ð»Ð¸ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ ÑÐ»Ð¾Ð¶Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð½Ð°ÑˆÐ¸Ñ… Ñ€ÐµÐ±ÑÑ‚.",
            description="Additional context â€” previous CRM experience",
        ),
        # === TURN 5: inject budget ===
        ConversationTurn(
            message="Ð‘ÑŽÐ´Ð¶ÐµÑ‚ Ñƒ Ð½Ð°Ñ Ð³Ð´Ðµ-Ñ‚Ð¾ Ð² Ñ€Ð°Ð¹Ð¾Ð½Ðµ 2 Ð¼Ð¸Ð»Ð»Ð¸Ð¾Ð½Ð¾Ð² Ñ€ÑƒÐ±Ð»ÐµÐ¹ Ð½Ð° Ð³Ð¾Ð´, Ð¼Ð¾Ð¶ÐµÑ‚ Ñ‡ÑƒÑ‚ÑŒ Ð±Ð¾Ð»ÑŒÑˆÐµ.",
            description="Inject budget_range",
        ),
        # === TURN 6-7: normal conversation (filler) ===
        ConversationTurn(
            message="Ð”Ð°, Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾. Ð ÐºÐ°Ðº Ñƒ Ð²Ð°Ñ Ñ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸ÐµÐ¹ Ñ 1Ð¡? Ð­Ñ‚Ð¾ Ð´Ð»Ñ Ð½Ð°Ñ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð¾.",
            description="Technical question (filler)",
        ),
        ConversationTurn(
            message="Ð Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ð¾Ðµ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ ÐµÑÑ‚ÑŒ? ÐÐ°ÑˆÐ¸ Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»Ð¸ Ð² Ñ€Ð°Ð·ÑŠÐµÐ·Ð´Ð°Ñ… Ð¿Ð¾ÑÑ‚Ð¾ÑÐ½Ð½Ð¾.",
            description="Technical question (filler)",
        ),
        # === TURN 8: PROBE for company_name (distance=7) ===
        ConversationTurn(
            message="Ð¢Ð°Ðº, Ð´Ð°Ð²Ð°Ð¹Ñ‚Ðµ Ð¿Ð¾Ð´Ñ‹Ñ‚Ð¾Ð¶Ð¸Ð¼ â€” Ñ‡Ñ‚Ð¾ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾ Ð²Ñ‹ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸Ñ‚ÑŒ Ð´Ð»Ñ Ð½Ð°ÑˆÐµÐ¹ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸?",
            description="PROBE: should mention ÐÐµÑ„Ñ‚ÐµÐ¢Ñ€Ð°Ð½ÑÐ¡ÐµÑ€Ð²Ð¸Ñ (distance=7)",
            is_probe=True,
            probe_fact="company_name",
            expect_in_response=["ÐÐµÑ„Ñ‚ÐµÐ¢Ñ€Ð°Ð½ÑÐ¡ÐµÑ€Ð²Ð¸Ñ"],
        ),
        # === TURN 9: PROBE for contact_name (distance=8) ===
        ConversationTurn(
            message="Ð Ð¼Ð¾Ð¶ÐµÑ‚Ðµ ÐµÑ‰Ñ‘ Ñ€Ð°Ð· Ð¾Ð±ÑŠÑÑÐ½Ð¸Ñ‚ÑŒ Ð¼Ð½Ðµ Ð»Ð¸Ñ‡Ð½Ð¾, ÐºÐ°ÐºÐ¸Ðµ Ð¿Ñ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð° Ð¸Ð¼ÐµÐ½Ð½Ð¾ Ð´Ð»Ñ Ð¼ÐµÐ½Ñ ÐºÐ°Ðº Ñ€ÑƒÐºÐ¾Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»Ñ?",
            description="PROBE: should address ÐÐ»ÐµÐºÑÐµÐ¹ ÐŸÐµÑ‚Ñ€Ð¾Ð²Ð¸Ñ‡ (distance=8)",
            is_probe=True,
            probe_fact="contact_name",
            expect_in_response=["ÐÐ»ÐµÐºÑÐµÐ¹"],
        ),
        # === TURN 10: PROBE for employee_count (distance=8) ===
        ConversationTurn(
            message="Ð Ñƒ Ð²Ð°Ñ Ñ‚Ð°Ñ€Ð¸Ñ„ Ð·Ð°Ð²Ð¸ÑÐ¸Ñ‚ Ð¾Ñ‚ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹? Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð½Ð°Ð¼ Ð½ÑƒÐ¶Ð½Ð¾ Ð»Ð¸Ñ†ÐµÐ½Ð·Ð¸Ð¹?",
            description="PROBE: should reference 450 employees (distance=8)",
            is_probe=True,
            probe_fact="employee_count",
            expect_in_response=["450"],
        ),
        # === TURN 11: PROBE for pain_point (distance=8) ===
        ConversationTurn(
            message="ÐÐ°Ð¿Ð¾Ð¼Ð½Ð¸Ñ‚Ðµ, ÐºÐ°Ðº Ð¸Ð¼ÐµÐ½Ð½Ð¾ Ð²Ð°Ñˆ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚ Ñ€ÐµÑˆÐ¸Ñ‚ Ð½Ð°ÑˆÐ¸ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹?",
            description="PROBE: should reference Excel/manual tracking (distance=8)",
            is_probe=True,
            probe_fact="pain_point",
            expect_in_response=["excel", "Ñ€ÑƒÑ‡Ð½"],
        ),
        # === TURN 12: second probe for company_name (distance=11) ===
        ConversationTurn(
            message="Ð¥Ð¾Ñ€Ð¾ÑˆÐ¾, Ð° ÐµÑÑ‚ÑŒ ÐºÐµÐ¹ÑÑ‹ Ð¸Ð· Ð½Ð°ÑˆÐµÐ¹ Ð¾Ñ‚Ñ€Ð°ÑÐ»Ð¸? Ð§Ñ‚Ð¾Ð±Ñ‹ Ð¼Ñ‹ Ð¼Ð¾Ð³Ð»Ð¸ ÑÑ€Ð°Ð²Ð½Ð¸Ñ‚ÑŒ.",
            description="PROBE: should reference our company/industry context (distance=11)",
            is_probe=True,
            probe_fact="company_name",
            expect_in_response=["Ð»Ð¾Ð³Ð¸ÑÑ‚Ð¸Ðº", "Ñ‚Ñ€Ð°Ð½ÑÐ¿Ð¾Ñ€Ñ‚", "Ð½ÐµÑ„Ñ‚"],
        ),
        # === TURN 13: PROBE for budget (distance=8) ===
        ConversationTurn(
            message="Ð”Ð°Ð²Ð°Ð¹Ñ‚Ðµ Ð¿Ð¾ Ð´ÐµÐ½ÑŒÐ³Ð°Ð¼ â€” Ð²Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ÑÑ Ð² Ð½Ð°Ñˆ Ð±ÑŽÐ´Ð¶ÐµÑ‚ Ð¸Ð»Ð¸ Ð½ÐµÑ‚?",
            description="PROBE: should reference 2 million budget (distance=8)",
            is_probe=True,
            probe_fact="budget_range",
            expect_in_response=["2 Ð¼Ð¸Ð»Ð»Ð¸Ð¾Ð½", "2 Ð¼Ð»Ð½", "Ð±ÑŽÐ´Ð¶ÐµÑ‚"],
        ),
        # === TURN 14-15: more filler ===
        ConversationTurn(
            message="Ð ÑÑ€Ð¾ÐºÐ¸ Ð²Ð½ÐµÐ´Ñ€ÐµÐ½Ð¸Ñ ÐºÐ°ÐºÐ¸Ðµ? ÐÐ°Ð¼ Ð½ÑƒÐ¶Ð½Ð¾ Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒÑÑ Ð´Ð¾ ÐºÐ¾Ð½Ñ†Ð° ÐºÐ²Ð°Ñ€Ñ‚Ð°Ð»Ð°.",
            description="Timeline question (filler)",
        ),
        ConversationTurn(
            message="Ð¢ÐµÑ…Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° Ñƒ Ð²Ð°Ñ 24/7 Ð¸Ð»Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð² Ñ€Ð°Ð±Ð¾Ñ‡ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ?",
            description="Support question (filler)",
        ),
        # === TURN 16: late PROBE for pain_point (distance=13) ===
        ConversationTurn(
            message="Ð¡Ð»ÑƒÑˆÐ°Ð¹Ñ‚Ðµ, Ð° Ð²Ð¾Ñ‚ Ð½Ð°ÑˆÐ° Ð³Ð»Ð°Ð²Ð½Ð°Ñ Ð±Ð¾Ð»ÑŒ ÐºÐ¾Ñ‚Ð¾Ñ€ÑƒÑŽ Ñ Ð¾Ð¿Ð¸ÑÑ‹Ð²Ð°Ð» Ð² Ð½Ð°Ñ‡Ð°Ð»Ðµ â€” Ð²Ñ‹ Ñ‚Ð¾Ñ‡Ð½Ð¾ ÐµÑ‘ Ñ€ÐµÑˆÐ¸Ñ‚Ðµ?",
            description="PROBE: explicit reference to early pain_point (distance=13)",
            is_probe=True,
            probe_fact="pain_point",
            expect_in_response=["excel", "Ñ€ÑƒÑ‡Ð½", "Ð·Ð°ÑÐ²Ðº", "ÑƒÑ‡Ñ‘Ñ‚"],
        ),
        # === TURN 17: late PROBE for all facts combined ===
        ConversationTurn(
            message="ÐžÐº, Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÑŒÑ‚Ðµ Ð¼Ð½Ðµ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ñ€ÐµÐ·ÑŽÐ¼Ðµ Ð½Ð°ÑˆÐµÐ³Ð¾ Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€Ð° â€” Ñ‡Ñ‚Ð¾ Ð¼Ñ‹ Ð¾Ð±ÑÑƒÐ´Ð¸Ð»Ð¸, Ñ‡Ñ‚Ð¾ Ñ€ÐµÑˆÐ¸Ð»Ð¸.",
            description="PROBE: summary request â€” should reference ALL early facts",
            is_probe=True,
            probe_fact="summary_all",
            expect_in_response=["ÐÐµÑ„Ñ‚ÐµÐ¢Ñ€Ð°Ð½ÑÐ¡ÐµÑ€Ð²Ð¸Ñ", "450", "Excel"],
        ),
    ],
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Scenario 2: SESSION RESTORE â€” context after save/load
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SCENARIO_SESSION_RESTORE = {
    "name": "Session Restore â€” context survival after snapshot",
    "description": """
    Tests what happens to context when a conversation is saved to snapshot
    and then restored. Verifies that episodic memory, collected data,
    and history_compact survive the round-trip.
    """,
    "fact_markers": [
        FactMarker("company_name", "Ð¢ÐµÑ…Ð½Ð¾ÐœÐ°Ñ€ÐºÐµÑ‚", 1, [7], ["Ð¢ÐµÑ…Ð½Ð¾ÐœÐ°Ñ€ÐºÐµÑ‚", "Ñ‚ÐµÑ…Ð½Ð¾Ð¼Ð°Ñ€ÐºÐµÑ‚"]),
        FactMarker("pain_point", "Ð¿Ð¾Ñ‚ÐµÑ€Ñ Ð»Ð¸Ð´Ð¾Ð² Ð¸Ð·-Ð·Ð° Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ñ CRM", 2, [7], ["Ð»Ð¸Ð´", "Ð¿Ð¾Ñ‚ÐµÑ€", "crm"]),
    ],
    "turns": [
        ConversationTurn(
            message="Ð—Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹Ñ‚Ðµ, Ñ Ð¸Ð· ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸ Ð¢ÐµÑ…Ð½Ð¾ÐœÐ°Ñ€ÐºÐµÑ‚, Ñƒ Ð½Ð°Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚-Ð¼Ð°Ð³Ð°Ð·Ð¸Ð½ ÑÐ»ÐµÐºÑ‚Ñ€Ð¾Ð½Ð¸ÐºÐ¸.",
            description="Inject company_name",
        ),
        ConversationTurn(
            message="ÐÐ°ÑˆÐ° Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° â€” Ð¿Ð¾ÑÑ‚Ð¾ÑÐ½Ð½Ð¾ Ñ‚ÐµÑ€ÑÐµÐ¼ Ð»Ð¸Ð´Ñ‹, Ð¿Ð¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾ Ð½ÐµÑ‚ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ CRM, Ð²ÑÑ‘ Ð² Ð³Ð¾Ð»Ð¾Ð²Ð°Ñ… Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€Ð¾Ð².",
            description="Inject pain_point",
        ),
        ConversationTurn(
            message="Ð’ ÐºÐ¾Ð¼Ð°Ð½Ð´Ðµ Ð¿Ñ€Ð¾Ð´Ð°Ð¶ Ñƒ Ð½Ð°Ñ 25 Ñ‡ÐµÐ»Ð¾Ð²ÐµÐº.",
            description="More context",
        ),
        ConversationTurn(
            message="Ð”Ð°, Ð¿Ñ€Ð¾Ð±Ð¾Ð²Ð°Ð»Ð¸ Ð‘Ð¸Ñ‚Ñ€Ð¸ÐºÑ24, Ð½Ðµ Ð¿Ð¾Ð´Ð¾ÑˆÑ‘Ð» â€” ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð¿ÐµÑ€ÐµÐ³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ð¹.",
            description="Previous experience",
        ),
        # === SAVE SNAPSHOT HERE (after turn 4) ===
        # === RESTORE FROM SNAPSHOT ===
        ConversationTurn(
            message="Ð¢Ð°Ðº, Ð½Ð° Ñ‡Ñ‘Ð¼ Ð¼Ñ‹ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ð»Ð¸ÑÑŒ? Ð Ð°ÑÑÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ñ‡Ñ‚Ð¾ Ð²Ñ‹ Ð¿Ð¾Ð½ÑÐ»Ð¸ Ð¾ Ð½Ð°ÑˆÐ¸Ñ… Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð½Ð¾ÑÑ‚ÑÑ….",
            description="POST-RESTORE PROBE: should remember Ð¢ÐµÑ…Ð½Ð¾ÐœÐ°Ñ€ÐºÐµÑ‚ + pain (after restore)",
            is_probe=True,
            probe_fact="company_name",
            expect_in_response=["Ð¢ÐµÑ…Ð½Ð¾ÐœÐ°Ñ€ÐºÐµÑ‚"],
        ),
        ConversationTurn(
            message="Ð Ñ‡Ñ‚Ð¾ Ð¸Ð¼ÐµÐ½Ð½Ð¾ Ð²Ñ‹ Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ‚Ðµ Ð´Ð»Ñ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð½Ð°ÑˆÐµÐ¹ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ñ Ð»Ð¸Ð´Ð°Ð¼Ð¸?",
            description="POST-RESTORE PROBE: should remember pain_point (after restore)",
            is_probe=True,
            probe_fact="pain_point",
            expect_in_response=["Ð»Ð¸Ð´", "Ð¿Ð¾Ñ‚ÐµÑ€"],
        ),
    ],
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Scenario 3: REPETITION STRESS â€” does bot loop in long dialogs?
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SCENARIO_REPETITION = {
    "name": "Repetition Stress â€” dedup check over 12 turns",
    "description": """
    Tests if the bot starts repeating itself in a long conversation
    where the user asks similar (but not identical) questions.
    Measures Jaccard similarity between consecutive responses.
    """,
    "fact_markers": [],
    "turns": [
        ConversationTurn(message="ÐŸÑ€Ð¸Ð²ÐµÑ‚, Ñ€Ð°ÑÑÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ð¾ Ð²Ð°ÑˆÐµÐ¼ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ðµ.", description="Initial question"),
        ConversationTurn(message="Ð ÐºÐ°ÐºÐ¸Ðµ ÐµÑÑ‚ÑŒ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸?", description="Features question v1"),
        ConversationTurn(message="Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾. Ð Ñ€Ð°ÑÑÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½ÐµÐµ Ð¿Ñ€Ð¾ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸.", description="Features question v2 (similar)"),
        ConversationTurn(message="Ð¥Ð¾Ñ€Ð¾ÑˆÐ¾, Ð° ÐµÑ‰Ñ‘ ÐºÐ°ÐºÐ¾Ð¹ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð» ÐµÑÑ‚ÑŒ?", description="Features question v3 (similar)"),
        ConversationTurn(message="ÐŸÐ¾Ð½ÑÑ‚Ð½Ð¾. Ð ÐºÐ°ÐºÐ¸Ðµ ÐµÑ‰Ñ‘ ÐµÑÑ‚ÑŒ Ñ„Ð¸Ñ‡Ð¸ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð²Ñ‹ Ð½Ðµ ÑƒÐ¿Ð¾Ð¼ÑÐ½ÑƒÐ»Ð¸?", description="Features question v4 (similar)"),
        ConversationTurn(message="Ð Ñ‡ÐµÐ¼ Ð²Ñ‹ Ð»ÑƒÑ‡ÑˆÐµ ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð²?", description="Competition question v1"),
        ConversationTurn(message="Ð ÐµÑÐ»Ð¸ ÑÑ€Ð°Ð²Ð½Ð¸Ñ‚ÑŒ Ñ Ð´Ñ€ÑƒÐ³Ð¸Ð¼Ð¸ CRM â€” Ð² Ñ‡Ñ‘Ð¼ Ð¿Ñ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð¾?", description="Competition question v2 (similar)"),
        ConversationTurn(message="ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ Ð¸Ð¼ÐµÐ½Ð½Ð¾ Ð²Ð°Ñ ÑÑ‚Ð¾Ð¸Ñ‚ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ Ð° Ð½Ðµ Ð´Ñ€ÑƒÐ³Ð¾Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ?", description="Competition question v3 (similar)"),
        ConversationTurn(message="ÐšÐ°ÐºÐ¸Ðµ ÐµÑÑ‚ÑŒ Ñ‚Ð°Ñ€Ð¸Ñ„Ñ‹?", description="Pricing v1"),
        ConversationTurn(message="Ð ÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÑ‚Ð¾Ð¸Ñ‚? Ð•ÑÑ‚ÑŒ Ð±ÐµÑÐ¿Ð»Ð°Ñ‚Ð½Ñ‹Ð¹ Ñ‚Ð°Ñ€Ð¸Ñ„?", description="Pricing v2 (similar)"),
        ConversationTurn(message="Ð Ñ†ÐµÐ½Ð° Ð·Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ ÐºÐ°ÐºÐ°Ñ?", description="Pricing v3 (similar)"),
        ConversationTurn(message="Ð ÐµÐ·ÑŽÐ¼Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð²ÑÑ‘ Ñ‡Ñ‚Ð¾ Ð²Ñ‹ Ð¼Ð½Ðµ Ñ€Ð°ÑÑÐºÐ°Ð·Ð°Ð»Ð¸.", description="Summary request"),
    ],
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Analysis Utilities
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def jaccard_similarity(text1: str, text2: str) -> float:
    """Compute Jaccard similarity between two texts (word-level)."""
    if not text1 or not text2:
        return 0.0
    words1 = set(text1.lower().split())
    words2 = set(text2.lower().split())
    intersection = words1 & words2
    union = words1 | words2
    return len(intersection) / len(union) if union else 0.0


def check_keywords(text: str, keywords: List[str]) -> Tuple[List[str], List[str]]:
    """Check which keywords are present/absent in text."""
    text_lower = text.lower()
    found = []
    missing = []
    for kw in keywords:
        if kw.lower() in text_lower:
            found.append(kw)
        else:
            missing.append(kw)
    return found, missing


def analyze_context_window(bot: SalesBot) -> Dict[str, Any]:
    """Extract context window state for analysis."""
    cw = bot.context_window
    em = cw.episodic_memory

    return {
        "cw_turns": len(cw.turns),
        "episodic_episodes": len(em.episodes),
        "episodic_total_turns": em.total_turns,
        "episodic_pain_points": list(em.client_profile.pain_points) if em.client_profile else [],
        "episodic_client_data": {
            "company_name": em.client_profile.company_name,
            "company_size": em.client_profile.company_size,
            "industry": em.client_profile.industry,
            "role": em.client_profile.role,
        } if em.client_profile else {},
        "episodic_all_objections": dict(em.all_objections),
        "episodic_successful_actions": dict(em.successful_actions),
        "episodic_failed_actions": dict(em.failed_actions),
        "first_objection_recorded": em._first_objection_recorded,
        "breakthrough_recorded": em._breakthrough_recorded,
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Test Runner
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_scenario(
    scenario: Dict[str, Any],
    flow_name: str,
    compact_output: bool = False,
    save_restore_after: Optional[int] = None,
) -> ScenarioResult:
    """Run a single test scenario."""
    name = scenario["name"]
    turns_def = scenario["turns"]
    fact_markers = scenario.get("fact_markers", [])

    print(f"\n{'=' * 80}")
    print(f"  SCENARIO: {name}")
    print(f"  Flow: {flow_name} | Turns: {len(turns_def)} | Fact markers: {len(fact_markers)}")
    print(f"{'=' * 80}")

    llm = OllamaLLM()
    bot = SalesBot(llm=llm, flow_name=flow_name, enable_tracing=True)

    result = ScenarioResult(
        scenario_name=name,
        flow_name=flow_name,
        turns=[],
        fact_markers=fact_markers,
        total_turns=len(turns_def),
    )

    prev_response = ""
    start_total = time.time()

    for i, turn_def in enumerate(turns_def):
        turn_num = i + 1

        # === SESSION SAVE/RESTORE ===
        if save_restore_after and turn_num == save_restore_after + 1:
            print(f"\n  {'â”€' * 70}")
            print(f"  âŸ³ SNAPSHOT SAVE/RESTORE after turn {save_restore_after}")
            # Grab last N turns of history BEFORE snapshot (snapshot stores empty history)
            history_before = list(bot.history)
            tail_size = 4
            history_tail = history_before[-tail_size:] if len(history_before) >= tail_size else history_before

            snapshot = bot.to_snapshot(compact_history=True, history_tail_size=tail_size)
            # Show compact info
            hc = snapshot.get("history_compact")
            if hc:
                print(f"    history_compact keys: {list(hc.keys())}")
                for k, v in hc.items():
                    if isinstance(v, list):
                        print(f"      {k}: {v[:3]}{'...' if len(v) > 3 else ''}")
            else:
                print(f"    history_compact: None (not generated)")

            hc_meta = snapshot.get("history_compact_meta")
            if hc_meta:
                print(f"    compact_meta: compacted_turns={hc_meta.get('compacted_turns')}, tail_size={hc_meta.get('tail_size')}")

            print(f"    Full history before snapshot: {len(history_before)} turns")
            print(f"    History tail passed to restore: {len(history_tail)} turns")

            # Restore with explicit history_tail
            bot_restored = SalesBot.from_snapshot(snapshot, llm=llm, history_tail=history_tail)
            print(f"    Restored bot history: {len(bot_restored.history)} turns")
            print(f"    Restored bot history_compact: {'yes' if bot_restored.history_compact else 'no'}")
            print(f"    Restored CW episodes: {len(bot_restored.context_window.episodic_memory.episodes)}")
            bot = bot_restored
            print(f"  {'â”€' * 70}")

        # === Send message ===
        start = time.time()
        try:
            result_dict = bot.process(turn_def.message)
            response = result_dict.get("response", "[NO RESPONSE]")
        except Exception as e:
            response = f"[ERROR: {e}]"
        elapsed = (time.time() - start) * 1000

        # Extract state info
        current_state = bot.state_machine.state
        last_intent = bot.last_intent or "?"

        # Analyze context window
        cw_info = analyze_context_window(bot)

        # History analysis
        history_len = len(bot.history)
        # Approximate formatted history length
        formatted = bot.generator.format_history(
            bot.history,
            use_full=(flow_name == "autonomous"),
        )
        history_formatted_len = len(formatted)

        # Fact checks for probe turns
        fact_checks = {}
        if turn_def.is_probe and turn_def.expect_in_response:
            for kw in turn_def.expect_in_response:
                fact_checks[kw] = kw.lower() in response.lower()

        # Similarity to previous response
        sim = jaccard_similarity(response, prev_response)

        turn_result = TurnResult(
            turn_num=turn_num,
            user_message=turn_def.message,
            bot_response=response,
            intent=last_intent,
            state=current_state,
            description=turn_def.description,
            history_len=history_len,
            history_formatted_len=history_formatted_len,
            cw_turns=cw_info["cw_turns"],
            episodic_episodes=cw_info["episodic_episodes"],
            episodic_pain_points=cw_info["episodic_pain_points"],
            episodic_client_data=cw_info["episodic_client_data"],
            fact_checks=fact_checks,
            similarity_to_prev=sim,
            elapsed_ms=elapsed,
        )
        result.turns.append(turn_result)
        prev_response = response

        # === Print turn ===
        status = ""
        if turn_def.is_probe:
            found_kw, missing_kw = check_keywords(response, turn_def.expect_in_response)
            if not missing_kw:
                status = "âœ… ALL FACTS FOUND"
                result.facts_retained += len(found_kw)
            elif found_kw:
                status = f"âš ï¸  PARTIAL ({len(found_kw)}/{len(turn_def.expect_in_response)})"
                result.facts_retained += len(found_kw)
                result.facts_lost += len(missing_kw)
            else:
                status = "âŒ FACTS LOST"
                result.facts_lost += len(turn_def.expect_in_response)

        if sim > 0.65:
            result.dedup_violations += 1

        if not compact_output:
            print(f"\n  Turn {turn_num:2d} | {turn_def.description}")
            print(f"  {'â”€' * 70}")
            print(f"  User: {turn_def.message[:100]}{'...' if len(turn_def.message) > 100 else ''}")
            print(f"  Bot:  {response[:200]}{'...' if len(response) > 200 else ''}")
            print(f"  Intent: {last_intent} | State: {current_state} | {elapsed:.0f}ms")
            print(f"  History: {history_len} turns (formatted: {history_formatted_len} chars)")
            print(f"  CW: {cw_info['cw_turns']}/5 turns | Episodes: {cw_info['episodic_episodes']}")
            if cw_info["episodic_pain_points"]:
                print(f"  Pain points (episodic): {cw_info['episodic_pain_points']}")
            if cw_info["episodic_client_data"].get("company_name"):
                print(f"  Client data (episodic): {cw_info['episodic_client_data']}")
            if status:
                print(f"  >>> {status}")
                if turn_def.is_probe:
                    found_kw, missing_kw = check_keywords(response, turn_def.expect_in_response)
                    if missing_kw:
                        print(f"      Missing: {missing_kw}")
                    if found_kw:
                        print(f"      Found:   {found_kw}")
            if sim > 0.5:
                print(f"  Similarity to prev: {sim:.2f} {'âš ï¸ HIGH' if sim > 0.65 else ''}")
        else:
            probe_flag = f" {status}" if status else ""
            print(f"  T{turn_num:2d} | {last_intent:30s} | {current_state:20s} | {elapsed:5.0f}ms | hist={history_len:2d} fmt={history_formatted_len:5d}ch | cw={cw_info['cw_turns']} ep={cw_info['episodic_episodes']:2d}{probe_flag}")

    result.total_elapsed_s = time.time() - start_total
    result.avg_response_len = (
        sum(len(t.bot_response) for t in result.turns) / len(result.turns)
        if result.turns else 0
    )
    result.history_compact_used = bot.history_compact is not None

    return result


def print_summary(results: List[ScenarioResult]):
    """Print final summary across all scenarios."""
    print(f"\n{'â•' * 80}")
    print(f"  FINAL SUMMARY")
    print(f"{'â•' * 80}")

    total_retained = sum(r.facts_retained for r in results)
    total_lost = sum(r.facts_lost for r in results)
    total_probes = total_retained + total_lost
    total_dedup = sum(r.dedup_violations for r in results)

    for r in results:
        probes = r.facts_retained + r.facts_lost
        pct = (r.facts_retained / probes * 100) if probes else 0
        print(f"\n  {r.scenario_name} [{r.flow_name}]")
        print(f"    Turns: {r.total_turns} | Time: {r.total_elapsed_s:.1f}s | Avg response: {r.avg_response_len:.0f} chars")
        print(f"    Fact retention: {r.facts_retained}/{probes} ({pct:.0f}%)")
        print(f"    Dedup violations (Jaccard > 0.65): {r.dedup_violations}")
        print(f"    history_compact stored: {'yes' if r.history_compact_used else 'no'}")

    if total_probes:
        print(f"\n  {'â”€' * 70}")
        print(f"  OVERALL FACT RETENTION: {total_retained}/{total_probes} ({total_retained/total_probes*100:.0f}%)")
        print(f"  OVERALL DEDUP VIOLATIONS: {total_dedup}")

    # === Detailed per-marker analysis ===
    print(f"\n  {'â”€' * 70}")
    print(f"  FACT RETENTION BY DISTANCE (turns between injection and probe):")
    print(f"  {'â”€' * 70}")

    for r in results:
        if not r.fact_markers:
            continue
        print(f"\n  [{r.scenario_name} / {r.flow_name}]")
        for fm in r.fact_markers:
            for check_turn in fm.check_at:
                if check_turn > len(r.turns):
                    continue
                distance = check_turn - fm.injected_at
                turn_result = r.turns[check_turn - 1]
                # Check if any of the marker's keywords were found
                response_lower = turn_result.bot_response.lower()
                found = any(kw.lower() in response_lower for kw in fm.check_keywords)
                status = "âœ…" if found else "âŒ"
                print(f"    {status} {fm.name:20s} | injected@T{fm.injected_at} â†’ checked@T{check_turn} (distance={distance:2d}) | history_window={turn_result.history_len}")

    # === Context Window / Episodic Memory analysis ===
    print(f"\n  {'â”€' * 70}")
    print(f"  EPISODIC MEMORY STATE AT KEY TURNS:")
    print(f"  {'â”€' * 70}")

    for r in results:
        if not r.turns:
            continue
        key_turns = [0, len(r.turns) // 2, len(r.turns) - 1]
        for idx in key_turns:
            t = r.turns[idx]
            print(f"\n  [{r.scenario_name}] Turn {t.turn_num}:")
            print(f"    CW turns: {t.cw_turns}/5 | Episodes: {t.episodic_episodes}")
            print(f"    Pain points: {t.episodic_pain_points or '(none)'}")
            cd = t.episodic_client_data
            if cd and cd.get("company_name"):
                print(f"    Client: company={cd.get('company_name')}, size={cd.get('company_size')}, industry={cd.get('industry')}")

    # === History window analysis ===
    print(f"\n  {'â”€' * 70}")
    print(f"  HISTORY WINDOW GROWTH:")
    print(f"  {'â”€' * 70}")
    for r in results:
        print(f"\n  [{r.scenario_name} / {r.flow_name}]")
        for t in r.turns:
            bar = "â–ˆ" * min(t.history_formatted_len // 100, 50)
            print(f"    T{t.turn_num:2d}: history={t.history_len:2d} turns, formatted={t.history_formatted_len:5d} chars {bar}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    parser = argparse.ArgumentParser(description="E2E Context Memory Stress Test")
    parser.add_argument("--flow", default=None, help="Run only this flow (e.g., autonomous, spin_selling)")
    parser.add_argument("--compact", action="store_true", help="Compact output (summary per turn)")
    parser.add_argument("--scenario", default=None, help="Run only this scenario (long, restore, repeat)")
    parser.add_argument("--json", default=None, help="Save results to JSON file")
    args = parser.parse_args()

    flows = [args.flow] if args.flow else ["autonomous", "spin_selling"]
    scenarios = []

    if not args.scenario or args.scenario == "long":
        scenarios.append(("long", SCENARIO_LONG_DIALOG, None))
    if not args.scenario or args.scenario == "restore":
        scenarios.append(("restore", SCENARIO_SESSION_RESTORE, 4))  # save/restore after turn 4
    if not args.scenario or args.scenario == "repeat":
        scenarios.append(("repeat", SCENARIO_REPETITION, None))

    all_results = []

    for flow_name in flows:
        for (label, scenario, save_after) in scenarios:
            try:
                result = run_scenario(
                    scenario=scenario,
                    flow_name=flow_name,
                    compact_output=args.compact,
                    save_restore_after=save_after,
                )
                all_results.append(result)
            except Exception as e:
                print(f"\n  âŒ SCENARIO FAILED: {scenario['name']} [{flow_name}]")
                print(f"     Error: {e}")
                import traceback
                traceback.print_exc()

    print_summary(all_results)

    # Save JSON results
    if args.json:
        json_data = []
        for r in all_results:
            scenario_data = {
                "scenario": r.scenario_name,
                "flow": r.flow_name,
                "total_turns": r.total_turns,
                "facts_retained": r.facts_retained,
                "facts_lost": r.facts_lost,
                "dedup_violations": r.dedup_violations,
                "total_elapsed_s": r.total_elapsed_s,
                "avg_response_len": r.avg_response_len,
                "history_compact_used": r.history_compact_used,
                "turns": [
                    {
                        "turn": t.turn_num,
                        "user": t.user_message,
                        "bot": t.bot_response,
                        "intent": t.intent,
                        "state": t.state,
                        "history_len": t.history_len,
                        "history_formatted_len": t.history_formatted_len,
                        "cw_turns": t.cw_turns,
                        "episodic_episodes": t.episodic_episodes,
                        "episodic_pain_points": t.episodic_pain_points,
                        "episodic_client_data": t.episodic_client_data,
                        "fact_checks": t.fact_checks,
                        "similarity_to_prev": t.similarity_to_prev,
                        "elapsed_ms": t.elapsed_ms,
                    }
                    for t in r.turns
                ],
            }
            json_data.append(scenario_data)

        with open(args.json, "w", encoding="utf-8") as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        print(f"\n  Results saved to: {args.json}")

    # Final verdict
    total_probes = sum(r.facts_retained + r.facts_lost for r in all_results)
    total_retained = sum(r.facts_retained for r in all_results)
    if total_probes:
        retention_pct = total_retained / total_probes * 100
        if retention_pct >= 80:
            print(f"\n  ðŸŸ¢ VERDICT: Good context retention ({retention_pct:.0f}%)")
        elif retention_pct >= 50:
            print(f"\n  ðŸŸ¡ VERDICT: Moderate context retention ({retention_pct:.0f}%) â€” consider expanding history window")
        else:
            print(f"\n  ðŸ”´ VERDICT: Poor context retention ({retention_pct:.0f}%) â€” critical issues with context management")


if __name__ == "__main__":
    main()
